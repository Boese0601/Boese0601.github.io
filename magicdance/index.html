<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MagicDance: Realistic Human Dance Video Generation
with Motions & Facial Expressions Transfer.">
  <meta name="keywords" content="Controllable Human Dance, Video Generation, Diffusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MagicDance: Realistic Human Dance Video Generation
with Motions & Facial Expressions Transfer.</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/tiktok.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MagicDance: Realistic Human Dance <br> Video Generation
with Motions & Facial Expressions Transfer</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://boese0601.github.io/">Di Chang</a><sup>1,2</sup>,&nbsp;&nbsp;</span> 
            <span class="author-block">
              <a href="https://seasonsh.github.io">Yichun Shi</a><sup>2</sup>,&nbsp;&nbsp;</span>
            <span class="author-block">
              <a href="https://zerg-overmind.github.io/">Quankai Gao</a><sup>1</sup>,&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/jessica-fu-60a504254/">Jessica Fu</a><sup>1</sup>,&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://hongyixu37.github.io/homepage/">Hongyi Xu</a><sup>2</sup>, &nbsp;&nbsp;
            </span><br>
            <span class="author-block">
              <a href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a><sup>2</sup>,&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=0TIYjPAAAAAJ&hl=en">Qing Yan</a><sup>2</sup>,&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en">Xiao Yang</a><sup>2</sup>,&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://www.ihp-lab.org/">Mohammad Soleymani</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Southern California,</span>
            <span class="author-block"><sup>2</sup>ByteDance Inc</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=VPJe6TyrT-Y"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Boese0601/MagicDance"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <img src="static/images/CVPR_Teaser_cropped.jpeg" alt="empty">
        <p>
          <br />
          We propose MagicDance, a novel and effective approach to provide realistic human video generation enabling vivid motion and facial expression transfer, and consistent 2D cartoon-style animation zero-shot generation without any fine-tuning. MagicDance can precisely generate appearance-consistent results, while the original text-to-image model (e.g., Stable Diffusion and ControlNet) can hardly maintain the subject identity information accurately. Furthermore, our proposed modules can be treated as an extension/plug-in to the original text-to-image model without modifying its pre-trained weight.
        </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           In this work, we propose MagicDance, a diffusion-based model for 2D human motion and facial expression transfer on challenging human dance video. Specifically, we aim to generate human dance videos of any target identity driven by novel pose sequences while keeping the identity unchanged. To this end, we propose a two-stage training strategy to disentangle human motions and appearance (e.g. facial expressions), consisting of the pretraining of an appearance-control block and finetuning of a appearance-pose-joint-control block over human dance poses of the same dataset. Compared to previous methods, the main contributions of our approach are highlight as three-fold: 1) Our novel design enables robust appearance control with time-consistent half-body, facial attributes, and even background. 2) Our model generalizes well on unseen human identities and complex motion sequences without the need of any finetuning on additional data with diverse human attributes, by properly leveraging the prior of controlnet pretrained over Internet-scale images. 3) Our model is easy-to-use, and can be considered as a plug-in module/extension to Stable Diffusion. %- Without finetuning Stable-Diffusion UNet (Your model weight is safe, as described in ControlNet).
4) We support zero-shot 2D animation generation and enable appearance transfer from not only one identity to another, but also allows for cartoon-like stylization given only pose inputs. Extensive experiments demonstrate our state-of-the-art performance with over TikTok and Everybodydancenow Datasets.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="./static/images/demo/main_4.mp4"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>

        <!-- Interpolating. -->
        <img src="./static/images/Pipeline.jpg" class="interpolation-image" alt="Interpolate start reference image."/>
        <p>
          <br />
          Overview of the proposed MagicDance pipeline for controllable human dance video generation with motions & facial expressions transfer. The Appearance Control Model is a copy of the entire Stable-Diffusion UNet, initialized with the same weight. The Stable-Diffusion UNet is fixed throughout the training. During a) Appearance Control Pretraining, we train the appearance control model and its Multi-Source Self-Attention Module. During b) Appearance-disentangled Pose Control, we jointly finetune the Appearance Control Model, initialized with weights from a), and the Pose ControlNet. After these steps, we freeze all previously trained modules and finetune a motion module initialized with AnimateDiff
        </p>
      <!--/ Interpolating. -->
      </div>
    </div>
    <!--/ Method. -->
    <br />
    <!-- Results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
        <h3 class="title is-4">1. Human Motion and Facial Expression Transfer</h3>
        <img src="./static/images/Supp_TikTok_1.jpg" class="interpolation-image" alt="Empty"/>
        <br />
        <img src="./static/images/Supp_TikTok_2.jpg" class="interpolation-image" alt="Empty"/>
        <br />
        <p>
          Visualization of Human Motion and Facial Expression Transfer. MagicDance is able to generate vivid and realistic motion and expressions under the condition of diverse pose skeleton and face landmark input, while accurately maintaining identity information from the reference image input.
        </p>
        <br />
        <h4 class="title is-5">Video Results</h4>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/demo/pose.gif"
                 alt="Interpolate start reference image."
                 width="300" />
            <p>Condition</p>
          </div>
          <div class="column has-text-centered">
            <img src="./static/images/demo/reference.jpeg"
                 alt="Interpolation end reference image."
                 width="100%" />
            <p>Reference</p>
          </div>
        </div>
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/images/demo/gen.mp4" type="video/mp4">
        </video>
        <p><center>Generated video</center></p>
        <!-- <br />
        <br />
        <br />
        <br />
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/demo/pose.gif"
                 alt="Interpolate start reference image."
                 width="300" />
            <p>Condition</p>
          </div>
          <div class="column has-text-centered">
            <img src="./static/images/demo/ref_1.jpeg"
                 alt="Interpolation end reference image."
                 width="100%" />
            <p>Reference</p>
          </div>
        </div>
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/images/demo/gen_1.mp4" type="video/mp4">
        </video>
        <p><center>Generated video</center></p>
        <br /> -->
        <br />
        <h3 class="title is-4">2. Zero-Shot Animation</h3>
        <img src="./static/images/animation.jpg" class="interpolation-image" alt="Empty"/>
        <br />
        <img src="./static/images/Figure11_cropped.jpg" class="interpolation-image" alt="Empty"/>
        <br />
        <p>
          <br />
          Visualization of Zero-Shot 2D Animation Generation. MagicDance can provide a precise generation with identity information from cartoon-style images even without any further fine-tuning after being trained on real-human dance videos.
        </p>
        <br />
        <h4 class="title is-5">Video Results</h4>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/videos/pose.gif"
                 alt="Interpolate start reference image."
                 width="180" />
            <p>Condition</p>
          </div>
          <div class="column has-text-centered">
            <img src="./static/images/reference.png"
                 alt="Interpolation end reference image."
                 width="100%" />
            <p>Reference</p>
          </div>
        </div>
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/gen.mp4" type="video/mp4">
        </video>
        <p><center>Generated video</center></p>
        <br />
        <br />
        <br />
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/demo/pose.gif"
                 alt="Interpolate start reference image."
                 width="130" />
            <p>Condition</p>
          </div>
          <div class="column has-text-centered">
            <img src="./static/images/demo/civitai.png"
                 alt="Interpolation end reference image."
                 width="1000" />
            <p>Reference</p>
          </div>
        </div>
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/images/demo/civitai.mp4" type="video/mp4">
        </video>
        <p><center>Generated video</center></p>
        <br />
      </div>
    </div>
    <!--/ Results. -->
    <br />
    <!-- Compare -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Comparison to Recent Works</h2>
        <h3 class="title is-4">Qualitative Compare</h3>
        <br />
        <img src="./static/images/comparison_cropped.jpeg" class="interpolation-image" alt="Empty"/>
        <p>
          <br />
          Qualitative comparison of human video generation between <a href="https://github.com/yoyo-nb/Thin-Plate-Spline-Motion-Model">TPS</a>, <a href="https://disco-dance.github.io/">Disco</a> and MagicDance. Previous methods obviously suffer from inconsistent facial expressions and human pose identity.
        </p>
        <br />
        <h4 class="title is-5">Video Comparison</h4>
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/0.mp4" type="video/mp4">
        </video>
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/1.mp4" type="video/mp4">
        </video>
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/2.mp4" type="video/mp4">
        </video>
        <p><center>
          <span style="margin: 0 73px">GT</span>
          <span style="margin: 0 73px">Pose</span>
          <span style="margin: 0 73px">TPS</span>
          <span style="margin: 0 73px">Disco</span>
          <span style="margin: 0 73px">MagicDance</span>
        </center></p>
        <br />
        <br />
        <h3 class="title is-4">Quantitative Compare</h3>
        <br />
        <img src="./static/images/table1.jpeg" class="interpolation-image" alt="Empty"/>
        <br />
        <p>
          Quantitative comparisons of MagicDance with the recent SOTA methods <a href="https://grail.cs.washington.edu/projects/dreampose/">DreamPose</a> and <a href="https://disco-dance.github.io/">Disco</a>. &#8595; indicates that the lower the better, and vice versa. Methods with * directly use the target image as the input, including more information compared to the OpenPose. &dagger; represents that Disco is pre-trained on other datasets more than our proposed MagicDance, which uses only 335 video sequences in the TikTok dataset for pretraning and fine-tuning. <b>Face-Cos</b> represents the cosine similarity of the face area between generation and ground truth image.
        </p>
      </div>
    </div>
    <!--/ Compare. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
